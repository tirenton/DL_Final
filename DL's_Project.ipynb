{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# ğŸ”¹ Install dependencies\n",
        "# ======================================\n",
        "!pip install yfinance PyPortfolioOpt torch torchvision torchaudio --quiet\n"
      ],
      "metadata": {
        "id": "huLX0eY9Mz2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "923ac771-82a6-4afe-bbdb-d5ff46c69f62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/62.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m61.4/62.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/222.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m222.1/222.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CmZTlcDYCjH_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# ğŸ”¹ Load Multi-Asset / Macro Data\n",
        "# ======================================\n",
        "def safe_load(symbol, start=\"2018-01-01\"):\n",
        "    data = yf.download(symbol, start=start)\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        close_col = data.columns[-1]  # à¹ƒà¸Šà¹‰à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ (yfinance auto-adjust)\n",
        "        return data[close_col].rename(symbol)\n",
        "    return None\n",
        "\n",
        "assets = [\"BTC-USD\", \"^GSPC\", \"GC=F\", \"^IXIC\"]  # Bitcoin, S&P500, Gold, NASDAQ\n",
        "dfs = [safe_load(sym) for sym in assets]\n",
        "df = pd.concat(dfs, axis=1).dropna()\n",
        "print(\"âœ… Data loaded:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdEn20MaObKW",
        "outputId": "0e7f7b02-7635-47ea-d3e8-d317c1a87e06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3788204494.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(symbol, start=start)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-3788204494.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(symbol, start=start)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-3788204494.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(symbol, start=start)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-3788204494.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(symbol, start=start)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data loaded: (1969, 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 3) Feature engineering (Multi-asset + Regime)\n",
        "# ======================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# H = horizon à¸§à¸±à¸™à¸¥à¹ˆà¸§à¸‡à¸«à¸™à¹‰à¸² (à¹à¸à¹‰à¹€à¸›à¹‡à¸™ 30 à¹„à¸”à¹‰)\n",
        "H = 3\n",
        "base = df.copy().astype(float)     # df à¸¡à¸²à¸ˆà¸²à¸à¸ªà¹ˆà¸§à¸™à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¸­à¸‡à¸„à¸¸à¸“\n",
        "\n",
        "def rsi_14(x: pd.Series):\n",
        "    up = x.diff().clip(lower=0).rolling(14, min_periods=14).mean()\n",
        "    dn = x.diff().clip(upper=0).abs().rolling(14, min_periods=14).mean()\n",
        "    return 100 - (100/(1 + (up/dn)))\n",
        "\n",
        "new_features = {}\n",
        "for c in base.columns:\n",
        "    price = base[c].replace(0, np.nan)\n",
        "\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        lr = np.log(price/price.shift(1))\n",
        "    new_features[f\"{c}_logret\"] = lr.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    new_features[f\"{c}_vol\"] = price.pct_change().rolling(14, min_periods=14).std()\n",
        "    new_features[f\"{c}_rsi\"] = rsi_14(price)\n",
        "\n",
        "feat_df = pd.DataFrame(new_features, index=base.index)\n",
        "\n",
        "# ----- BTC-specific -----\n",
        "btc = base[\"BTC-USD\"]\n",
        "feat_df[\"BTC-USD_ma7\"]      = btc.rolling(7,  min_periods=7).mean()\n",
        "feat_df[\"BTC-USD_ma21\"]     = btc.rolling(21, min_periods=21).mean()\n",
        "feat_df[\"BTC-USD_momentum\"] = btc / btc.shift(10) - 1\n",
        "macd_fast = btc.ewm(12, adjust=False).mean()\n",
        "macd_slow = btc.ewm(26, adjust=False).mean()\n",
        "macd = macd_fast - macd_slow\n",
        "feat_df[\"BTC-USD_macd\"]   = macd\n",
        "feat_df[\"BTC-USD_signal\"] = macd.ewm(9, adjust=False).mean()\n",
        "\n",
        "# ----- Cross-asset correlations (14D) -----\n",
        "if all(x in base.columns for x in [\"BTC-USD\",\"^GSPC\",\"GC=F\",\"^IXIC\"]):\n",
        "    feat_df[\"SP500_corr\"]  = base[\"BTC-USD\"].rolling(14, min_periods=14).corr(base[\"^GSPC\"])\n",
        "    feat_df[\"GOLD_corr\"]   = base[\"BTC-USD\"].rolling(14, min_periods=14).corr(base[\"GC=F\"])\n",
        "    feat_df[\"NASDAQ_corr\"] = base[\"BTC-USD\"].rolling(14, min_periods=14).corr(base[\"^IXIC\"])\n",
        "\n",
        "# ----- Regime features: 30D realized vol à¸‚à¸­à¸‡ BTC -----\n",
        "btc_vol30 = btc.pct_change().rolling(30, min_periods=30).std()\n",
        "feat_df[\"BTC_vol30\"] = btc_vol30\n",
        "q1, q2 = btc_vol30.quantile([0.33, 0.66])\n",
        "feat_df[\"regime_low\"]  = (btc_vol30 <= q1).astype(float)\n",
        "feat_df[\"regime_mid\"]  = ((btc_vol30 > q1) & (btc_vol30 <= q2)).astype(float)\n",
        "feat_df[\"regime_high\"] = (btc_vol30 > q2).astype(float)\n",
        "\n",
        "# ----- à¸£à¸§à¸¡ + target -----\n",
        "data = pd.concat([base, feat_df], axis=1)\n",
        "data[\"target\"] = (data[\"BTC-USD\"].shift(-H) > data[\"BTC-USD\"]).astype(int)\n",
        "\n",
        "# clean\n",
        "data = data.replace([np.inf, -np.inf], np.nan).dropna().reset_index(drop=True)\n",
        "print(\"âœ… Feature table:\", data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkKzMQC0YWvE",
        "outputId": "bfffa90c-79dc-419b-9dc6-11c33ea7bad4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3449916581.py:24: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  new_features[f\"{c}_vol\"] = price.pct_change().rolling(14, min_periods=14).std()\n",
            "/tmp/ipython-input-3449916581.py:24: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  new_features[f\"{c}_vol\"] = price.pct_change().rolling(14, min_periods=14).std()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Feature table: (1660, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 4) Prepare dataset (split, scale, sequence)\n",
        "# ======================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# à¹€à¸¥à¸·à¸­à¸à¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¹„à¸§à¹‰à¹ƒà¸™ Step 3\n",
        "feature_keys = [\"logret\",\"_vol\",\"_rsi\",\"ma\",\"momentum\",\"macd\",\"signal\",\"_corr\",\"regime_\",\"BTC_vol30\"]\n",
        "features = [c for c in data.columns if any(k in c for k in feature_keys)]\n",
        "\n",
        "assert \"target\" in data.columns, \"à¹„à¸¡à¹ˆà¸à¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ target à¸ˆà¸²à¸à¸‚à¸±à¹‰à¸™à¸—à¸µà¹ˆ 3\"\n",
        "assert len(features) > 0, \"à¹„à¸¡à¹ˆà¸à¸šà¸Ÿà¸µà¹€à¸ˆà¸­à¸£à¹Œà¸ˆà¸²à¸à¸‚à¸±à¹‰à¸™à¸—à¸µà¹ˆ 3\"\n",
        "\n",
        "# à¹à¸¢à¸ train/val à¸•à¸²à¸¡à¹€à¸§à¸¥à¸² (à¹„à¸¡à¹ˆà¸ªà¸¥à¸±à¸šà¸¥à¸³à¸”à¸±à¸š)\n",
        "split = int(len(data)*0.8)\n",
        "train_df = data.iloc[:split].copy()\n",
        "val_df   = data.iloc[split:].copy()\n",
        "\n",
        "# scale à¹€à¸‰à¸à¸²à¸°à¸šà¸™ train à¹à¸¥à¹‰à¸§à¸„à¹ˆà¸­à¸¢ transform val à¹€à¸à¸·à¹ˆà¸­à¸à¸±à¸™ data leakage\n",
        "scaler = StandardScaler()\n",
        "train_df[features] = scaler.fit_transform(train_df[features])\n",
        "val_df[features]   = scaler.transform(val_df[features])\n",
        "\n",
        "# à¸—à¸³à¹€à¸›à¹‡à¸™à¸¥à¸³à¸”à¸±à¸šà¹€à¸§à¸¥à¸²\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, frame, fcols, seq_len=128):\n",
        "        X, y = [], []\n",
        "        vals = frame[fcols].values\n",
        "        tars = frame[\"target\"].values.astype(np.float32)\n",
        "        for i in range(len(frame) - seq_len):\n",
        "            X.append(vals[i:i+seq_len])\n",
        "            y.append(tars[i+seq_len])\n",
        "        self.X = torch.tensor(np.array(X), dtype=torch.float32)\n",
        "        self.y = torch.tensor(np.array(y), dtype=torch.float32).unsqueeze(1)\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "SEQ_LEN = 128\n",
        "BATCH   = 64\n",
        "train_loader = DataLoader(SeqDataset(train_df, features, SEQ_LEN), batch_size=BATCH, shuffle=True)\n",
        "val_loader   = DataLoader(SeqDataset(val_df,   features, SEQ_LEN), batch_size=BATCH, shuffle=False)\n",
        "\n",
        "print(f\"train_size={len(train_df)}  val_size={len(val_df)}  n_features={len(features)}\")\n"
      ],
      "metadata": {
        "id": "EdN5buNjR7ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7498bb-de7f-49f4-938c-11aec13d758d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_size=1328  val_size=332  n_features=24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 5) GRU model (regularized)\n",
        "# ======================================\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256, layers=3, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=in_dim,\n",
        "            hidden_size=hidden,\n",
        "            num_layers=layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if layers > 1 else 0.0\n",
        "        )\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.out  = nn.Linear(hidden, 1)  # binary logit\n",
        "    def forward(self, x):\n",
        "        h, _ = self.gru(x)           # (B, T, H)\n",
        "        h_last = h[:, -1, :]         # (B, H)\n",
        "        h_last = self.drop(h_last)\n",
        "        return self.out(h_last)      # (B, 1)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model  = GRUModel(in_dim=len(features), hidden=256, layers=3, dropout=0.5).to(device)\n"
      ],
      "metadata": {
        "id": "lWPmUuxqKMSG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 6) Train / Evaluate utils (Early stopping + Cosine LR)\n",
        "# ======================================\n",
        "def eval_model(model, loader, threshold=0.5):\n",
        "    model.eval()\n",
        "    y_true, y_prob, tot = [], [], 0.0\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logit = model(xb)\n",
        "            loss  = loss_fn(logit, yb)\n",
        "            tot  += loss.item()\n",
        "            prob  = torch.sigmoid(logit).cpu().numpy().ravel()\n",
        "            y_prob.extend(prob)\n",
        "            y_true.extend(yb.cpu().numpy().ravel())\n",
        "    y_true = np.array(y_true); y_prob = np.array(y_prob)\n",
        "    y_pred = (y_prob > threshold).astype(int)\n",
        "    # à¸à¸±à¸™à¹€à¸„à¸ª all-one/all-zero\n",
        "    if len(np.unique(y_true)) < 2:\n",
        "        f1, auc, acc = 0.0, 0.5, (y_pred==y_true).mean()\n",
        "    else:\n",
        "        f1  = f1_score(y_true, y_pred, zero_division=0)\n",
        "        auc = roc_auc_score(y_true, y_prob)\n",
        "        acc = (y_pred==y_true).mean()\n",
        "    return tot/len(loader), f1, auc, acc, y_true, y_prob\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=200, lr=2e-4, patience=10):\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(20, epochs//2), eta_min=1e-6)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    best_val = np.inf\n",
        "    patience_ctr = 0\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"f1\": [], \"auc\": [], \"acc\": []}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logit  = model(xb)\n",
        "            loss   = loss_fn(logit, yb)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            total += loss.item()\n",
        "        scheduler.step()\n",
        "\n",
        "        val_loss, f1, auc, acc, _, _ = eval_model(model, val_loader, threshold=0.5)\n",
        "        history[\"train_loss\"].append(total/len(train_loader))\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"f1\"].append(f1)\n",
        "        history[\"auc\"].append(auc)\n",
        "        history[\"acc\"].append(acc)\n",
        "\n",
        "        print(f\"Epoch {ep:03d}: train={total/len(train_loader):.4f}  val={val_loss:.4f}  F1={f1:.3f}  AUC={auc:.3f}  ACC={acc:.3f}\")\n",
        "\n",
        "        # early stopping à¸•à¸±à¸”à¸ªà¸´à¸™à¸”à¹‰à¸§à¸¢ val_loss\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss\n",
        "            patience_ctr = 0\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "        else:\n",
        "            patience_ctr += 1\n",
        "            if patience_ctr >= patience:\n",
        "                print(f\"â¹ï¸ Early stopping at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "    if 'best_state' in locals():\n",
        "        model.load_state_dict(best_state)\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "dqPKnj0VKNeV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ğŸ”¹ Total features selected:\", len(features))\n",
        "print(features[:10], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOYS5mbZhY7r",
        "outputId": "5ebfe80d-459d-41ec-81d4-c18a1480566a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Total features selected: 24\n",
            "['BTC-USD_logret', 'BTC-USD_vol', 'BTC-USD_rsi', '^GSPC_logret', '^GSPC_vol', '^GSPC_rsi', 'GC=F_logret', 'GC=F_vol', 'GC=F_rsi', '^IXIC_logret'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 7) Train\n",
        "# ======================================\n",
        "model, history = train_model(model, train_loader, val_loader, epochs=200, lr=2e-4, patience=10)\n"
      ],
      "metadata": {
        "id": "MAiiHxS6KP-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 8) Pick threshold by F1 on validation\n",
        "# ======================================\n",
        "_, _, _, _, y_true_val, y_prob_val = eval_model(model, val_loader, threshold=0.5)\n",
        "\n",
        "ths = np.linspace(0.2, 0.8, 25)\n",
        "f1s, accs = [], []\n",
        "for t in ths:\n",
        "    pred = (y_prob_val > t).astype(int)\n",
        "    f1s.append(f1_score(y_true_val, pred, zero_division=0))\n",
        "    accs.append((pred == y_true_val).mean())\n",
        "\n",
        "best_idx = int(np.argmax(f1s))\n",
        "best_th  = float(ths[best_idx])\n",
        "print(f\"Best threshold (F1 on val) = {best_th:.3f}  F1={f1s[best_idx]:.3f}  ACC={accs[best_idx]:.3f}\")\n"
      ],
      "metadata": {
        "id": "ok9kj9GhKRY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 9) Final validation report + plots (ROC / PR / Loss curves)\n",
        "# ======================================\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\n",
        "\n",
        "# loss curves\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
        "plt.plot(history[\"val_loss\"],   label=\"Val Loss\")\n",
        "plt.legend(); plt.title(\"Loss Curves\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.show()\n",
        "\n",
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(y_true_val, y_prob_val)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, label=f\"AUC={roc_auc_score(y_true_val, y_prob_val):.3f}\")\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.legend(); plt.title(\"ROC (Validation)\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.show()\n",
        "\n",
        "# PR\n",
        "prec, rec, _ = precision_recall_curve(y_true_val, y_prob_val)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(rec, prec)\n",
        "plt.title(\"Precision-Recall (Validation)\"); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.show()\n",
        "\n",
        "# Confusion matrix at best_th\n",
        "y_pred_best = (y_prob_val > best_th).astype(int)\n",
        "cm = confusion_matrix(y_true_val, y_pred_best)\n",
        "print(\"Confusion matrix @ best_th:\\n\", cm)\n",
        "\n",
        "# à¸ªà¸£à¸¸à¸›à¸•à¸±à¸§à¹€à¸¥à¸‚à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ @ best_th\n",
        "final_f1  = f1_score(y_true_val, y_pred_best, zero_division=0)\n",
        "final_acc = (y_pred_best == y_true_val).mean()\n",
        "final_auc = roc_auc_score(y_true_val, y_prob_val)\n",
        "print(f\"Final (val)  AUC={final_auc:.3f}  F1@best_th={final_f1:.3f}  ACC@best_th={final_acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "FswnYx1JjZCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 10) Sanity checks: class balance à¹à¸¥à¸° distribution à¸‚à¸­à¸‡ prob\n",
        "# ======================================\n",
        "pos_rate = y_true_val.mean()\n",
        "print(f\"Positive ratio (val) = {pos_rate:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(y_prob_val, bins=30)\n",
        "plt.title(\"Predicted probability distribution (val)\")\n",
        "plt.xlabel(\"P(y=1)\"); plt.ylabel(\"count\"); plt.show()\n"
      ],
      "metadata": {
        "id": "31YDSacils6G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}